{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load visual language model subandhu\n",
    "# write code for reading document and converting the pages to image aditya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'frontend'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfitz\u001b[39;00m  \u001b[38;5;66;03m# PyMuPDF\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n",
      "File \u001b[1;32mc:\\Users\\KIIT\\anaconda\\envs\\Agents\\Lib\\site-packages\\fitz\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfrontend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtools\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpath\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mop\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'frontend'"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import os\n",
    "from PIL import Image\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from langchain_core.tools import BaseTool\n",
    "from langchain_core.agents import BaseAgent\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Annotated, Sequence\n",
    "import operator\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Initialize the model and tokenizer\n",
    "model_id = \"vikhyatk/moondream2\"\n",
    "revision = \"2024-05-20\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, trust_remote_code=True, revision=revision)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, revision=revision)\n",
    "\n",
    "# Step 1: Convert PDF to Images\n",
    "def convert_pdf_to_images(pdf_path, output_folder):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    pdf_document = fitz.open(pdf_path)\n",
    "    for page_num in range(len(pdf_document)):\n",
    "        page = pdf_document.load_page(page_num)\n",
    "        pix = page.get_pixmap()\n",
    "        image_path = os.path.join(output_folder, f\"page_{page_num + 1}.png\")\n",
    "        pix.save(image_path)\n",
    "    return [os.path.join(output_folder, f\"page_{i + 1}.png\") for i in range(len(pdf_document))]\n",
    "\n",
    "# Step 2: Define Tools\n",
    "class AadhaarTool(BaseTool):\n",
    "    name = \"aadhaar_extraction\"\n",
    "    description = \"Extracts address information from Aadhaar card images.\"\n",
    "\n",
    "    def __call__(self, image_path: str) -> dict:\n",
    "        image = Image.open(image_path)\n",
    "        enc_image = model.encode_image(image)\n",
    "        result = model.answer_question(enc_image, \"Extract address from this Aadhaar card.\", tokenizer)\n",
    "        return {\"address\": result}\n",
    "\n",
    "class PanTool(BaseTool):\n",
    "    name = \"pan_extraction\"\n",
    "    description = \"Extracts identity information from PAN card images.\"\n",
    "\n",
    "    def __call__(self, image_path: str) -> dict:\n",
    "        image = Image.open(image_path)\n",
    "        enc_image = model.encode_image(image)\n",
    "        result = model.answer_question(enc_image, \"Extract name and PAN number from this PAN card.\", tokenizer)\n",
    "        return {\"identity_info\": result}\n",
    "\n",
    "class VoterIDTool(BaseTool):\n",
    "    name = \"voterid_extraction\"\n",
    "    description = \"Extracts identity information from Voter ID images.\"\n",
    "\n",
    "    def __call__(self, image_path: str) -> dict:\n",
    "        image = Image.open(image_path)\n",
    "        enc_image = model.encode_image(image)\n",
    "        result = model.answer_question(enc_image, \"Extract name and Voter ID from this Voter ID card.\", tokenizer)\n",
    "        return {\"identity_info\": result}\n",
    "\n",
    "class AttributeTool(BaseTool):\n",
    "    name = \"attribute_extraction\"\n",
    "    description = \"Extracts specified attributes from the document images based on the prompt.\"\n",
    "\n",
    "    def __call__(self, image_path: str, attributes: list) -> dict:\n",
    "        image = Image.open(image_path)\n",
    "        enc_image = model.encode_image(image)\n",
    "        results = {}\n",
    "        for attr in attributes:\n",
    "            result = model.answer_question(enc_image, f\"Extract {attr} from this document.\", tokenizer)\n",
    "            results[attr] = result\n",
    "        return results\n",
    "\n",
    "# Step 3: Define Agents\n",
    "class ProofOfAddressAgent(BaseAgent):\n",
    "    def __init__(self, tool):\n",
    "        self.tool = tool\n",
    "\n",
    "    def __call__(self, state):\n",
    "        image_path = state[\"image_path\"]\n",
    "        address_info = self.tool(image_path)\n",
    "        return {\"address_info\": address_info}\n",
    "\n",
    "class ProofOfIdentityAgent(BaseAgent):\n",
    "    def __init__(self, tools):\n",
    "        self.tools = tools\n",
    "\n",
    "    def __call__(self, state):\n",
    "        image_path = state[\"image_path\"]\n",
    "        for tool in self.tools:\n",
    "            identity_info = tool(image_path)\n",
    "            if identity_info:\n",
    "                return {\"identity_info\": identity_info}\n",
    "        return {\"identity_info\": None}\n",
    "\n",
    "class AttributeExtractionAgent(BaseAgent):\n",
    "    def __init__(self, tool):\n",
    "        self.tool = tool\n",
    "\n",
    "    def __call__(self, state):\n",
    "        image_path = state[\"image_path\"]\n",
    "        attributes = state[\"attributes\"]\n",
    "        extracted_attributes = self.tool(image_path, attributes)\n",
    "        return {\"extracted_attributes\": extracted_attributes}\n",
    "\n",
    "class ReviewerAgent(BaseAgent):\n",
    "    def __call__(self, state):\n",
    "        address_info = state.get(\"address_info\")\n",
    "        identity_info = state.get(\"identity_info\")\n",
    "        extracted_attributes = state.get(\"extracted_attributes\")\n",
    "\n",
    "        if address_info and identity_info and extracted_attributes:\n",
    "            data = {**address_info, **identity_info, **extracted_attributes}\n",
    "            df = pd.DataFrame([data])\n",
    "            return {\"dataframe\": df}\n",
    "        else:\n",
    "            return {\"error\": \"Missing information\"}\n",
    "\n",
    "# Step 4: Integrate Agents into LangGraph\n",
    "class AgentState(TypedDict):\n",
    "    image_path: str\n",
    "    attributes: list\n",
    "    address_info: dict\n",
    "    identity_info: dict\n",
    "    extracted_attributes: dict\n",
    "\n",
    "def call_proof_of_address(state):\n",
    "    agent = ProofOfAddressAgent(AadhaarTool())\n",
    "    return agent(state)\n",
    "\n",
    "def call_proof_of_identity(state):\n",
    "    agent = ProofOfIdentityAgent([PanTool(), VoterIDTool()])\n",
    "    return agent(state)\n",
    "\n",
    "def call_attribute_extraction(state):\n",
    "    agent = AttributeExtractionAgent(AttributeTool())\n",
    "    return agent(state)\n",
    "\n",
    "def call_reviewer(state):\n",
    "    agent = ReviewerAgent()\n",
    "    return agent(state)\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"proof_of_address\", call_proof_of_address)\n",
    "workflow.add_node(\"proof_of_identity\", call_proof_of_identity)\n",
    "workflow.add_node(\"attribute_extraction\", call_attribute_extraction)\n",
    "workflow.add_node(\"reviewer\", call_reviewer)\n",
    "workflow.set_entry_point(\"proof_of_address\")\n",
    "\n",
    "workflow.add_edge(\"proof_of_address\", \"proof_of_identity\")\n",
    "workflow.add_edge(\"proof_of_identity\", \"attribute_extraction\")\n",
    "workflow.add_edge(\"attribute_extraction\", \"reviewer\")\n",
    "workflow.add_edge(\"reviewer\", END)\n",
    "\n",
    "app = workflow.compile()\n",
    "\n",
    "# Step 5: Process Each Page of the Document\n",
    "pdf_path = r\"C:\\Users\\KIIT\\Desktop\\who\\work\\skive.ai\\BGQPK4512E_31012024103628.pdf\"\n",
    "output_folder = \"output_images\"\n",
    "image_paths = convert_pdf_to_images(pdf_path, output_folder)\n",
    "attributes_to_extract = [\"DOB\", \"Issue Date\"]\n",
    "\n",
    "all_dataframes = []\n",
    "for image_path in image_paths:\n",
    "    inputs = {\n",
    "        \"image_path\": image_path,\n",
    "        \"attributes\": attributes_to_extract\n",
    "    }\n",
    "    output = app.invoke(inputs)\n",
    "    if \"dataframe\" in output:\n",
    "        all_dataframes.append(output[\"dataframe\"])\n",
    "\n",
    "# Combine all dataframes\n",
    "final_dataframe = pd.concat(all_dataframes, ignore_index=True)\n",
    "print(final_dataframe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pdf_path': 'C:\\\\Users\\\\KIIT\\\\Desktop\\\\who\\\\work\\\\skive.ai\\\\BGQPK4512E_31012024103628.pdf', 'output_folder': 'C:\\\\Users\\\\KIIT\\\\Desktop\\\\who\\\\work\\\\skive.ai', 'storage_folder': 'C:\\\\Users\\\\KIIT\\\\Desktop\\\\who\\\\work\\\\skive.ai', 'image_paths': ['C:\\\\Users\\\\KIIT\\\\Desktop\\\\who\\\\work\\\\skive.ai\\\\page_1.png', 'C:\\\\Users\\\\KIIT\\\\Desktop\\\\who\\\\work\\\\skive.ai\\\\page_2.png', 'C:\\\\Users\\\\KIIT\\\\Desktop\\\\who\\\\work\\\\skive.ai\\\\page_3.png', 'C:\\\\Users\\\\KIIT\\\\Desktop\\\\who\\\\work\\\\skive.ai\\\\page_4.png', 'C:\\\\Users\\\\KIIT\\\\Desktop\\\\who\\\\work\\\\skive.ai\\\\page_5.png', 'C:\\\\Users\\\\KIIT\\\\Desktop\\\\who\\\\work\\\\skive.ai\\\\page_6.png', 'C:\\\\Users\\\\KIIT\\\\Desktop\\\\who\\\\work\\\\skive.ai\\\\page_7.png', 'C:\\\\Users\\\\KIIT\\\\Desktop\\\\who\\\\work\\\\skive.ai\\\\page_8.png']}\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "from PIL import Image\n",
    "import os\n",
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, List, Annotated\n",
    "import operator\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    pdf_path: str\n",
    "    output_folder: str\n",
    "    storage_folder: str\n",
    "    image_paths: Annotated[List[str], operator.add]\n",
    "\n",
    "def convert_pdf_to_images(pdf_path, output_folder):\n",
    "    pdf_document = fitz.open(pdf_path)\n",
    "    image_paths = []\n",
    "    \n",
    "    for page_num in range(len(pdf_document)):\n",
    "        page = pdf_document.load_page(page_num)\n",
    "        pix = page.get_pixmap()\n",
    "        output_path = os.path.join(output_folder, f'page_{page_num + 1}.png')\n",
    "        pix.save(output_path)\n",
    "        image_paths.append(output_path)\n",
    "    \n",
    "    return image_paths\n",
    "\n",
    "def store_images(image_paths, storage_folder):\n",
    "    if not os.path.exists(storage_folder):\n",
    "        os.makedirs(storage_folder)\n",
    "    \n",
    "    for image_path in image_paths:\n",
    "        image = Image.open(image_path)\n",
    "        image.save(os.path.join(storage_folder, os.path.basename(image_path)))\n",
    "    \n",
    "    return {\"status\": \"success\", \"stored_images\": len(image_paths)}\n",
    "\n",
    "def call_convert_pdf_to_images(state):\n",
    "    pdf_path = state['pdf_path']\n",
    "    output_folder = state['output_folder']\n",
    "    image_paths = convert_pdf_to_images(pdf_path, output_folder)\n",
    "    return {\"image_paths\": image_paths}\n",
    "\n",
    "def call_store_images(state):\n",
    "    image_paths = state['image_paths']\n",
    "    storage_folder = state['storage_folder']\n",
    "    result = store_images(image_paths, storage_folder)\n",
    "    return result\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "workflow.add_node(\"convert_pdf_to_images\", call_convert_pdf_to_images)\n",
    "workflow.add_node(\"store_images\", call_store_images)\n",
    "\n",
    "workflow.set_entry_point(\"convert_pdf_to_images\")\n",
    "workflow.add_edge(\"convert_pdf_to_images\", \"store_images\")\n",
    "workflow.set_finish_point(\"store_images\")\n",
    "\n",
    "app = workflow.compile()\n",
    "\n",
    "inputs = {\n",
    "    \"pdf_path\": r\"C:\\Users\\KIIT\\Desktop\\who\\work\\skive.ai\\BGQPK4512E_31012024103628.pdf\",\n",
    "    \"output_folder\": r\"C:\\Users\\KIIT\\Desktop\\who\\work\\skive.ai\",\n",
    "    \"storage_folder\": r\"C:\\Users\\KIIT\\Desktop\\who\\work\\skive.ai\",\n",
    "    \"image_paths\": []\n",
    "}\n",
    "\n",
    "result = app.invoke(inputs)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "from PIL import Image\n",
    "import os\n",
    "from typing import TypedDict, List, Annotated, Dict\n",
    "import operator\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# Ensure required directories exist\n",
    "def ensure_directory_exists(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "# Convert PDF pages to images\n",
    "def convert_pdf_to_images(pdf_path, output_folder):\n",
    "    ensure_directory_exists(output_folder)\n",
    "    pdf_document = fitz.open(pdf_path)\n",
    "    image_paths = []\n",
    "    \n",
    "    for page_num in range(len(pdf_document)):\n",
    "        page = pdf_document.load_page(page_num)\n",
    "        pix = page.get_pixmap()\n",
    "        output_path = os.path.join(output_folder, f'page_{page_num + 1}.png')\n",
    "        pix.save(output_path)\n",
    "        image_paths.append(output_path)\n",
    "    \n",
    "    return image_paths\n",
    "\n",
    "# Store images in the specified folder\n",
    "def store_images(image_paths, storage_folder):\n",
    "    ensure_directory_exists(storage_folder)\n",
    "    \n",
    "    for image_path in image_paths:\n",
    "        image = Image.open(image_path)\n",
    "        image.save(os.path.join(storage_folder, os.path.basename(image_path)))\n",
    "    \n",
    "    return {\"status\": \"success\", \"stored_images\": len(image_paths)}\n",
    "\n",
    "# Reviewer agent: Extract information from each page based on user query\n",
    "def review_images(image_paths, query):\n",
    "    model_id = \"vikhyatk/moondream2\"\n",
    "    revision = \"2024-07-23\"\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_id, trust_remote_code=True, revision=revision)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id, revision=revision)\n",
    "    \n",
    "    results = {}\n",
    "    for image_path in image_paths:\n",
    "        image = Image.open(image_path)\n",
    "        enc_image = model.encode_image(image)\n",
    "        response = model.answer_question(enc_image, query, tokenizer)\n",
    "        results[image_path] = response\n",
    "    \n",
    "    return results\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    pdf_path: str\n",
    "    output_folder: str\n",
    "    storage_folder: str\n",
    "    query: str\n",
    "    image_paths: Annotated[List[str], operator.add]\n",
    "    review_results: Dict[str, str]\n",
    "\n",
    "def call_convert_pdf_to_images(state):\n",
    "    pdf_path = state['pdf_path']\n",
    "    output_folder = state['output_folder']\n",
    "    image_paths = convert_pdf_to_images(pdf_path, output_folder)\n",
    "    return {\"image_paths\": image_paths}\n",
    "\n",
    "def call_store_images(state):\n",
    "    image_paths = state['image_paths']\n",
    "    storage_folder = state['storage_folder']\n",
    "    result = store_images(image_paths, storage_folder)\n",
    "    return result\n",
    "\n",
    "def call_review_images(state):\n",
    "    image_paths = state['image_paths']\n",
    "    query = state['query']\n",
    "    review_results = review_images(image_paths, query)\n",
    "    return {\"review_results\": review_results}\n",
    "\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "workflow.add_node(\"convert_pdf_to_images\", call_convert_pdf_to_images)\n",
    "workflow.add_node(\"store_images\", call_store_images)\n",
    "workflow.add_node(\"review_images\", call_review_images)\n",
    "\n",
    "workflow.set_entry_point(\"convert_pdf_to_images\")\n",
    "workflow.add_edge(\"convert_pdf_to_images\", \"store_images\")\n",
    "workflow.add_edge(\"store_images\", \"review_images\")\n",
    "workflow.set_finish_point(\"review_images\")\n",
    "\n",
    "app = workflow.compile()\n",
    "prompt=\n",
    "inputs = {\n",
    "    \"pdf_path\": r\"C:\\Users\\KIIT\\Desktop\\who\\work\\skive.ai\\BGQPK4512E_31012024103628.pdf\",\n",
    "    \"output_folder\": r\"C:\\Users\\KIIT\\Desktop\\who\\work\\skive.ai\\Docs\",\n",
    "    \"storage_folder\": r\"C:\\Users\\KIIT\\Desktop\\who\\work\\skive.ai\\Docs\",\n",
    "    \"query\": \"Describe the main topic of this page.\",\n",
    "    \"image_paths\": [],\n",
    "    \"review_results\": {}\n",
    "}\n",
    "\n",
    "result = app.invoke(inputs)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\KIIT\\anaconda\\envs\\Agents\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\KIIT\\anaconda\\envs\\Agents\\Lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\KIIT\\.cache\\huggingface\\hub\\models--vikhyatk--moondream2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "from PIL import Image\n",
    "import os\n",
    "import pandas as pd\n",
    "from typing import TypedDict, List, Annotated, Dict\n",
    "import operator\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# Ensure required directories exist\n",
    "def ensure_directory_exists(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "# Convert PDF pages to images\n",
    "def convert_pdf_to_images(pdf_path, output_folder):\n",
    "    ensure_directory_exists(output_folder)\n",
    "    pdf_document = fitz.open(pdf_path)\n",
    "    image_paths = []\n",
    "    \n",
    "    for page_num in range(len(pdf_document)):\n",
    "        page = pdf_document.load_page(page_num)\n",
    "        pix = page.get_pixmap()\n",
    "        output_path = os.path.join(output_folder, f'page_{page_num + 1}.png')\n",
    "        pix.save(output_path)\n",
    "        image_paths.append(output_path)\n",
    "    \n",
    "    return image_paths\n",
    "\n",
    "# Store images in the specified folder\n",
    "def store_images(image_paths, storage_folder):\n",
    "    ensure_directory_exists(storage_folder)\n",
    "    \n",
    "    for image_path in image_paths:\n",
    "        image = Image.open(image_path)\n",
    "        image.save(os.path.join(storage_folder, os.path.basename(image_path)))\n",
    "    \n",
    "    return {\"status\": \"success\", \"stored_images\": len(image_paths)}\n",
    "\n",
    "# Reviewer agent: Extract information from each page based on user query\n",
    "def review_images(image_paths, query):\n",
    "    model_id = \"vikhyatk/moondream2\"\n",
    "    revision = \"2024-07-23\"\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_id, trust_remote_code=True, revision=revision)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id, revision=revision)\n",
    "    \n",
    "    results = {}\n",
    "    for image_path in image_paths:\n",
    "        image = Image.open(image_path)\n",
    "        enc_image = model.encode_image(image)\n",
    "        response = model.answer_question(enc_image, query, tokenizer)\n",
    "        results[image_path] = response\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Generate the detailed query\n",
    "def generate_query():\n",
    "    attributes = [\n",
    "        \"PAN Copy Present or not\",\n",
    "        \"PAN Number\",\n",
    "        \"Name\",\n",
    "        \"Gender\",\n",
    "        \"POA Copy Present or not\",\n",
    "        \"Type - UID, voter ID, Passport, Driver Licence\",\n",
    "        \"Name\",\n",
    "        \"Proof Number\",\n",
    "        \"Download date\",\n",
    "        \"Gender\",\n",
    "        \"c/o\",\n",
    "        \"Address [Pincode, State, City, locality, Landmark]\",\n",
    "        \"Signature present or not\",\n",
    "        \"Document\",\n",
    "        \"KYC Mode\",\n",
    "        \"Applicant Type\",\n",
    "        \"Name\",\n",
    "        \"Maiden Name\",\n",
    "        \"Father’s Name\",\n",
    "        \"DOB\",\n",
    "        \"Gender\",\n",
    "        \"Occupation\",\n",
    "        \"Residential status\",\n",
    "        \"Application Number\",\n",
    "        \"Marital Status\",\n",
    "        \"PAN Number\",\n",
    "        \"Nationality\",\n",
    "        \"Citizenship\",\n",
    "        \"Address type\",\n",
    "        \"Proof of address : Type\",\n",
    "        \"Residential Address {Line 123, state, country, pincode, city}\",\n",
    "        \"Email\",\n",
    "        \"Mobile\",\n",
    "        \"Corresponding address\",\n",
    "        \"Name & E code\",\n",
    "        \"Designation\",\n",
    "        \"Date\",\n",
    "        \"Intermediary Date\",\n",
    "        \"Esign Date\"\n",
    "    ]\n",
    "    \n",
    "    query = \"Please check if the following attributes are present in this document and extract the information: \" + \", \".join(attributes)\n",
    "    return query\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    pdf_path: str\n",
    "    output_folder: str\n",
    "    storage_folder: str\n",
    "    query: str\n",
    "    image_paths: Annotated[List[str], operator.add]\n",
    "    review_results: Dict[str, str]\n",
    "\n",
    "def call_convert_pdf_to_images(state):\n",
    "    pdf_path = state['pdf_path']\n",
    "    output_folder = state['output_folder']\n",
    "    image_paths = convert_pdf_to_images(pdf_path, output_folder)\n",
    "    return {\"image_paths\": image_paths}\n",
    "\n",
    "def call_store_images(state):\n",
    "    image_paths = state['image_paths']\n",
    "    storage_folder = state['storage_folder']\n",
    "    result = store_images(image_paths, storage_folder)\n",
    "    return result\n",
    "\n",
    "def call_review_images(state):\n",
    "    image_paths = state['image_paths']\n",
    "    query = state['query']\n",
    "    review_results = review_images(image_paths, query)\n",
    "    return {\"review_results\": review_results}\n",
    "\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "workflow.add_node(\"convert_pdf_to_images\", call_convert_pdf_to_images)\n",
    "workflow.add_node(\"store_images\", call_store_images)\n",
    "workflow.add_node(\"review_images\", call_review_images)\n",
    "\n",
    "workflow.set_entry_point(\"convert_pdf_to_images\")\n",
    "workflow.add_edge(\"convert_pdf_to_images\", \"store_images\")\n",
    "workflow.add_edge(\"store_images\", \"review_images\")\n",
    "workflow.set_finish_point(\"review_images\")\n",
    "\n",
    "app = workflow.compile()\n",
    "\n",
    "inputs = {\n",
    "    \"pdf_path\": r\"C:\\Users\\KIIT\\Desktop\\who\\work\\skive.ai\\BGQPK4512E_31012024103628.pdf\",\n",
    "    \"output_folder\": r\"C:\\Users\\KIIT\\Desktop\\who\\work\\skive.ai\\Docs\",\n",
    "    \"storage_folder\": r\"C:\\Users\\KIIT\\Desktop\\who\\work\\skive.ai\\Docs\",\n",
    "    \"query\": generate_query(),\n",
    "    \"image_paths\": [],\n",
    "    \"review_results\": {}\n",
    "}\n",
    "\n",
    "result = app.invoke(inputs)\n",
    "\n",
    "# Save the review results to a DataFrame\n",
    "review_results = result[\"review_results\"]\n",
    "df = pd.DataFrame.from_dict(review_results, orient='index')\n",
    "df.reset_index(inplace=True)\n",
    "df.rename(columns={'index': 'Image Path', 0: 'Extracted Information'}, inplace=True)\n",
    "\n",
    "# Save DataFrame to a CSV file\n",
    "df.to_csv('/path/to/output/folder/extracted_information.csv', index=False)\n",
    "\n",
    "print(\"Extraction complete. Results saved to extracted_information.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "from PIL import Image\n",
    "import os\n",
    "import pandas as pd\n",
    "import logging\n",
    "from typing import TypedDict, List, Annotated, Dict\n",
    "import operator\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Ensure required directories exist\n",
    "def ensure_directory_exists(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        logging.info(f\"Directory created: {directory}\")\n",
    "    else:\n",
    "        logging.info(f\"Directory already exists: {directory}\")\n",
    "\n",
    "# Convert PDF pages to images\n",
    "def convert_pdf_to_images(pdf_path, output_folder):\n",
    "    ensure_directory_exists(output_folder)\n",
    "    pdf_document = fitz.open(pdf_path)\n",
    "    image_paths = []\n",
    "    \n",
    "    for page_num in range(len(pdf_document)):\n",
    "        page = pdf_document.load_page(page_num)\n",
    "        pix = page.get_pixmap()\n",
    "        output_path = os.path.join(output_folder, f'page_{page_num + 1}.png')\n",
    "        pix.save(output_path)\n",
    "        image_paths.append(output_path)\n",
    "        logging.info(f\"Page {page_num + 1} converted to image: {output_path}\")\n",
    "    \n",
    "    return image_paths\n",
    "\n",
    "# Store images in the specified folder\n",
    "def store_images(image_paths, storage_folder):\n",
    "    ensure_directory_exists(storage_folder)\n",
    "    \n",
    "    for image_path in image_paths:\n",
    "        image = Image.open(image_path)\n",
    "        image.save(os.path.join(storage_folder, os.path.basename(image_path)))\n",
    "        logging.info(f\"Image stored: {image_path}\")\n",
    "    \n",
    "    return {\"status\": \"success\", \"stored_images\": len(image_paths)}\n",
    "\n",
    "# Reviewer agent: Extract information from each page based on user query\n",
    "def review_images(image_paths, query):\n",
    "    model_id = \"vikhyatk/moondream2\"\n",
    "    revision = \"2024-07-23\"\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_id, trust_remote_code=True, revision=revision)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id, revision=revision)\n",
    "    \n",
    "    results = {}\n",
    "    for image_path in image_paths:\n",
    "        logging.info(f\"Reviewing image: {image_path}\")\n",
    "        image = Image.open(image_path)\n",
    "        enc_image = model.encode_image(image)\n",
    "        response = model.answer_question(enc_image, query, tokenizer)\n",
    "        results[image_path] = response\n",
    "        logging.info(f\"Extracted information from {image_path}: {response}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Generate the detailed query\n",
    "def generate_query():\n",
    "    attributes = [\n",
    "        \"PAN Copy Present or not\",\n",
    "        \"PAN Number\",\n",
    "        \"Name\",\n",
    "        \"Gender\",\n",
    "        \"POA Copy Present or not\",\n",
    "        \"Type - UID, voter ID, Passport, Driver Licence\",\n",
    "        \"Name\",\n",
    "        \"Proof Number\",\n",
    "        \"Download date\",\n",
    "        \"Gender\",\n",
    "        \"c/o\",\n",
    "        \"Address [Pincode, State, City, locality, Landmark]\",\n",
    "        \"Signature present or not\",\n",
    "        \"Document\",\n",
    "        \"KYC Mode\",\n",
    "        \"Applicant Type\",\n",
    "        \"Name\",\n",
    "        \"Maiden Name\",\n",
    "        \"Father’s Name\",\n",
    "        \"DOB\",\n",
    "        \"Gender\",\n",
    "        \"Occupation\",\n",
    "        \"Residential status\",\n",
    "        \"Application Number\",\n",
    "        \"Marital Status\",\n",
    "        \"PAN Number\",\n",
    "        \"Nationality\",\n",
    "        \"Citizenship\",\n",
    "        \"Address type\",\n",
    "        \"Proof of address : Type\",\n",
    "        \"Residential Address {Line 123, state, country, pincode, city}\",\n",
    "        \"Email\",\n",
    "        \"Mobile\",\n",
    "        \"Corresponding address\",\n",
    "        \"Name & E code\",\n",
    "        \"Designation\",\n",
    "        \"Date\",\n",
    "        \"Intermediary Date\",\n",
    "        \"Esign Date\"\n",
    "    ]\n",
    "    \n",
    "    query = \"Please check if the following attributes are present in this document and extract the information: \" + \", \".join(attributes)\n",
    "    return query\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    pdf_path: str\n",
    "    output_folder: str\n",
    "    storage_folder: str\n",
    "    query: str\n",
    "    image_paths: Annotated[List[str], operator.add]\n",
    "    review_results: Dict[str, str]\n",
    "\n",
    "def call_convert_pdf_to_images(state):\n",
    "    pdf_path = state['pdf_path']\n",
    "    output_folder = state['output_folder']\n",
    "    logging.info(f\"Starting PDF to image conversion for {pdf_path}\")\n",
    "    image_paths = convert_pdf_to_images(pdf_path, output_folder)\n",
    "    logging.info(f\"PDF to image conversion completed. Images saved in {output_folder}\")\n",
    "    return {\"image_paths\": image_paths}\n",
    "\n",
    "def call_store_images(state):\n",
    "    image_paths = state['image_paths']\n",
    "    storage_folder = state['storage_folder']\n",
    "    logging.info(f\"Storing images in {storage_folder}\")\n",
    "    result = store_images(image_paths, storage_folder)\n",
    "    logging.info(f\"Image storage completed. Stored {result['stored_images']} images\")\n",
    "    return result\n",
    "\n",
    "def call_review_images(state):\n",
    "    image_paths = state['image_paths']\n",
    "    query = state['query']\n",
    "    logging.info(\"Starting image review with the query: \" + query)\n",
    "    review_results = review_images(image_paths, query)\n",
    "    logging.info(\"Image review completed\")\n",
    "    return {\"review_results\": review_results}\n",
    "\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "workflow.add_node(\"convert_pdf_to_images\", call_convert_pdf_to_images)\n",
    "workflow.add_node(\"store_images\", call_store_images)\n",
    "workflow.add_node(\"review_images\", call_review_images)\n",
    "\n",
    "workflow.set_entry_point(\"convert_pdf_to_images\")\n",
    "workflow.add_edge(\"convert_pdf_to_images\", \"store_images\")\n",
    "workflow.add_edge(\"store_images\", \"review_images\")\n",
    "workflow.set_finish_point(\"review_images\")\n",
    "\n",
    "app = workflow.compile()\n",
    "\n",
    "inputs = {\n",
    "    \"pdf_path\": r\"C:\\Users\\KIIT\\Desktop\\who\\work\\skive.ai\\BGQPK4512E_31012024103628.pdf\",\n",
    "    \"output_folder\": r\"C:\\Users\\KIIT\\Desktop\\who\\work\\skive.ai\\Docs\",\n",
    "    \"storage_folder\": r\"C:\\Users\\KIIT\\Desktop\\who\\work\\skive.ai\\Docs\",\n",
    "    \"query\": generate_query(),\n",
    "    \"image_paths\": [],\n",
    "    \"review_results\": {}\n",
    "}\n",
    "\n",
    "logging.info(\"Workflow execution started\")\n",
    "result = app.invoke(inputs)\n",
    "logging.info(\"Workflow execution completed\")\n",
    "\n",
    "# Save the review results to a DataFrame\n",
    "review_results = result[\"review_results\"]\n",
    "df = pd.DataFrame.from_dict(review_results, orient='index')\n",
    "df.reset_index(inplace=True)\n",
    "df.rename(columns={'index': 'Image Path', 0: 'Extracted Information'}, inplace=True)\n",
    "\n",
    "# Save DataFrame to a CSV file\n",
    "output_csv_path = os.path.join(inputs['output_folder'], 'extracted_information.csv')\n",
    "df.to_csv(output_csv_path, index=False)\n",
    "logging.info(f\"Extraction complete. Results saved to {output_csv_path}\")\n",
    "\n",
    "print(\"Extraction complete. Results saved to extracted_information.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
